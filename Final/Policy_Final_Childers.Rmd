---
title: 'EDS241: FINAL'
author: "Heather Childers"
output:
  html_document:
    toc: no
    df_print: paged
  pdf_document:
    toc: no
    number_sections: yes
header-includes: \setlength{\parindent}{1em} \usepackage{float} \renewcommand{\thesubsection}{Question
  (\alph{subsection})}
---

Make sure to read through the setup in markdown. Remember to write out interpretations and report your results in writing/table/plot forms.

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
#Clean Environment
rm(list=ls())

# Setup your coding process in a way that works for you. 
# Ideally use projects to organize your scripts and outputs. 
# You all probably know more about this than us! 
# For this project, I would create a project with all your data and scripts. 
# I often store data on servers rather than my computer which is why I use the code you see below.

# I set an extension to retrieve data from a particular place (Google Drive/servers etc) 
# and projects to organize my scripts and outputs on my computer/github.

# here I am setting a path to where I stored the data for this assignment
#data_wd <- "/Users/elliottfinn/Library/CloudStorage/GoogleDrive-elliottfinn@ucsb.edu/Shared drives/EDS241/Assignments/Assignment 2" 

# Example of how I use this Data Working Directory:
# data <- read_csv(paste0(data_wd,"/FILE_NAME.csv")) 
# This helps me download/manage my data from different places.

# set default chunk options
knitr::opts_chunk$set(fig.width = 4, fig.height = 3, 
                      echo = TRUE, message = FALSE, warning = FALSE)

# load packages
packages=c(
  # Necessary for Assignment 2
  "Match","plm", "tidyverse", "MatchIt", "RItools", "Hmisc", "lmtest", "estimatr",
  
  # You decide what works for you, these are the packages I use to display results 
  # they may not be the ones you use.
  "gridExtra", "stargazer", "kableExtra", 
  "purrr", "knitr", "broom",
  
  # Some Potentially useful packages from earlier examples
           "stargazer", "here","stringr", "janitor", 
           "cowplot", "ggplot2", "tinytex", "datasets", "tibble") # Used for Mock assignment

for (i in packages) {
  if (require(i,character.only=TRUE)==FALSE) {
    install.packages(i,repos='http://cran.us.r-project.org')
  }
  else {
    require(i,character.only=TRUE)
  }
}

# Disable scientific notation if you want
options(scipen=999)
library(ggplotify)
```

# Part 1: RCTs, treatment ignorability (selection on observables), propensity scores *(15 points total)*

**Setup**

This exercise is inspired by Costello et al. 2008 article in science "Can Catch Shares Prevent Fisheries Collapse", which we also discussed in class (lecture 5). "Inspired" means that the data final_fisheries_data.csv are synthetically generated to simplify things for our purposes. It contains the variables on 11,135 fisheries (only cross sectional, no time observations): These fisheries were either regulated by an Individual Transferable Quota (ITQ) for all years between 1990 and 2012 or in none of those years. Variables in the dataset include:

**The outcome and treatment variables are:**

\indent COLL_SHARE = share of years a fishery is collapsed between 1990 and 2012 (collapse defined as harvest being more than 10% below maximum recorded harvest).

\indent ITQ = dummy variable indicating 'treatment' with an ITQ (equal to 1 if the fishery has been regulated by an ITQ and 0 otherwise).

**The control variables are:**

\indent MET1, MET2, ....MET6 = Dummy variables indicating to which Marine Ecosystem Type (MET) the fishery belongs to (coral reefs, kelp forests, seagrass meadows, open ocean, deep sea, mangrove forests). This type does not change over the relevant time period and does not depend on human influence.

\indent IND_SR = Index of species richness in 1980 with values between 0 and 100 indicating the biodiversity with respect to species in the fishery. Bounds of 0 and 100 are the lowest and highest observed values of species diversity across all fisheries in 1980, respectively.

\indent COMM_VAL = Commercial value of fisheries in 1980 in million US-\$

The basic question of interest is "What is the average treatment effect of implementing an ITQ in the time period from 1990 to 2012 on the share of years with a collapse. It is likely that the probability a fishery is selected for an ITQ depends on the pre-treatment characteristics given. It is also quite likely that the pre-treatment characteristics have an effect on the share of collapse for each fishery, i.e. our outcome variable of interest.

```{r , include=TRUE}
## Load Data
fish_dat <- read_csv("data/final_fisheries_data.csv")

#Looking at the data
#head(fish_dat)
```

## Pretreatment Ecosystem Characteristic Comparison, Visual *(3 pts)*

(a) **Compare the distributions of pre-treatment ecosystem characteristics (i.e. MET1, MET2, ,,, MET6) between the treated and the control groups by drawing back to back histograms [2 pts]. Write one sentence discussing the (dis)similarity between the two groups [1pt].**

    It is clear from the histograms plotted below that the pre-treatment characteristics are not evenly distributed between the treated and non-treated group. This can be seen and further elaborated on in the rest of this section:

```{r , include=TRUE}
# Create separate data frames for treated and control groups
treated <- fish_dat %>% 
  filter(ITQ == 1)
control <- fish_dat %>% 
  filter(ITQ == 0)
```

The pre-treatment characteristic Marine Ecosystem Type 1 is equally distributed between the treated and non treated groups. For these comparisons, we are really only looking for equality in how many ecosystems identified as the ecosystem of interest, which is indicated in these histograms as a "1". This can be seen in the back-to back histogram shown below:

```{r}
# Create back-to-back histograms for each variable
MET1 <- histbackback(split(
fish_dat$MET1, fish_dat$ITQ),
main = "Marine Ecosystem Type 1",
xlab = c("Control", "Treatment"),
ylab = "Pre-treatment Characteristic")

```

The Marine Ecosystem Type 2 pre-treatment characteristic is also equally distributed between the treated and non-treated groups. This can be seen in the back-to-back histogram shown below:

```{r}
MET2 <- histbackback(split(
fish_dat$MET2, fish_dat$ITQ),
main = "Marine Ecosystem Type 2",
xlab = c("Control", "Treatment"),
ylab = "Pre-treatment Characteristic")

```

The Marine Ecosystem Type 3 pre-treatment characteristic is also equally distributed between the treated and non-treated groups. This can be seen in the back-to-back histogram shown below:

```{r}
MET3 <- histbackback(split(
fish_dat$MET3, fish_dat$ITQ),
main = "Marine Ecosystem Type 3",
xlab = c("Control", "Treatment"),
ylab = "Pre-treatment Characteristic")
```

The Marine Ecosystem Type 4 pre-treatment characteristic is roughly equally distributed between the treated and non-treated groups, however I think there are slightly more Type 4 ecosystems in the treated group. This can be seen in the back-to-back histogram below:

```{r}
MET4 <- histbackback(split(
fish_dat$MET4, fish_dat$ITQ),
main = "Marine Ecosystem Type 4",
xlab = c("Control", "Treatment"),
ylab = "Pre-treatment Characteristic")
```

The Marine Ecosystem Type 5 pre-treatment characteristic is looking much more skewed than our previous pre-treatment characteristics between the treated and non-treated groups, there is a noticeably higher amount of Type 5 ecosystems in the treated group. This can be seen in the back-to-back histogram below:

```{r}
MET5 <- histbackback(split(
fish_dat$MET5, fish_dat$ITQ),
main = "Marine Ecosystem Type 5",
xlab = c("Control", "Treatment"),
ylab = "Pre-treatment Characteristic")
```

The Marine Ecosystem Type 6 pre-treatment characteristic is equally distributed between the treated and non-treated groups. This can be seen in the back-to-back histogram shown below:

```{r}
MET6 <- histbackback(split(
fish_dat$MET6, fish_dat$ITQ),
main = "Marine Ecosystem Type 6",
xlab = c("Control", "Treatment"),
ylab = "Pre-treatment Characteristic")
```

There are two interesting things that make the species richness index have unequal distributions between the treated and non treated group, the first is that there are clearly more observations in the treated group than the control group, and the average species richness index seems to be noticably higher for the control group than the treated group. This can be seen in the back-to-back histogram below:

```{r}
IND_SR <- histbackback(split(
fish_dat$IND_SR, fish_dat$ITQ),
main = "Species Richness Index",
xlab = c("Control", "Treatment"),
ylab = "Pre-treatment Characteristic")
```

Similar to the species richness index, the commercial value pre-treatment characteristic is not equally distributed between the treatment and control groups. We can still see there are more individuals in the treated group, but it also looks like the avergae commercial value of the treated group is lower than that of the non-treated groups. This can be seen in the back-to-back histogram below:

```{r}
COMM_VAL <- histbackback(split(
fish_dat$COMM_VAL, fish_dat$ITQ),
main = "Commercial Value",
xlab = c("Control", "Treatment"),
ylab = "Million US$")
```

## Pretreatment Ecosystem Characteristic Comparison, Mean differences *3 pts)*

(b) **Do a test on mean differences between the treated and control groups for the species richness index (IND_SR) and commercial value (COMM_VAL) variables. Interpret the results (estimated difference and significance) [2 pts]**

Both of these estimates need t.tests because they are continuous variables rather than binary variables. Starting with the species richness index, the null hypothesis is that there is no difference in the means between the treated and non-treated groups. The average species richness index for the non-treated group is 57.385 and the average species richness index for the treated group is 48.559. This estimate for the difference in means was statistically significant beyond a level of 0.001, which means we can reject the null hypothesis and say there is a statistically significant non-zero difference in the average species richness index between the treated and non-treated groups.

For the commercial value, the null hypothesis is that there is no difference in the means between the treated and non-treated groups. The average commercial value for the non-treated group is 117.8 million US\$ and the average species richness index for the treated group is 84.9 million US\$. This estimate for the difference in means was statistically significant beyond a level of 0.001, which means we can reject the null hypothesis and say there is a statistically significant non-zero difference in the average commercial value between the treated and non-treated groups.

(b) **Make a conclusion regarding the similarity between the groups [1pt].**

These statistically significant differences in the average values of the pre-treatment characteristics show that these groups are not similar in their pre-treatment characteristics and the control group is not a good counter-factual for the treatment group in this study. If all the pre-treatment characteristics were randomly assigned, we would see equal distributions of the characteristics and statistically insignificant differences in means.

```{r , include=TRUE}
## Mean Differences (remember to use prop.test or t.test when applicable)
#t.test for the SR_index
t_test_sri <- t.test(IND_SR ~ ITQ, data = fish_dat)
## Present Results
t_test_sri

#t.test for the COMM_VAL
t_test_comval <- t.test(COMM_VAL ~ ITQ, data = fish_dat)
## Present Results
t_test_comval
```

## Treatment Ignorability *(1 pt)*

(c) Based on your results from (a) and (b), do you see a problem with just comparing the outcome variable means between treated and untreated fisheries?

Yes, there is a problem with comparing the means of the treated and non-treated fishery collapse rates. Since the pre-treatment characteristics are not evenly distributed between the treated and non-treated groups and there are statistically significant differences in the averages of the two variables we tested, there's reason to believe that some of the fishery collapses/successes could be due to the pre-treatment characteristics and not entirely caused by the Individual Transferable Quota. Because the pre-treatment characteristics could be affecting our outcome variable, we cannot simply compare the mean share of years a fishery is collapsed between the treatment and non-treatment groups to get the Average Treatment Effect.

## Propensity Scores *(2 pts)*

(d) **Estimate the propensity scores (probability of being treated) using a logit model, assume that all covariates are relevant and should be included in the estimation [0.5 pt]. Draw separate histograms (back to back) of the propensity scores for the treated and the untreated group [0.5 pt].**

    The coefficients on each covariate represent how the probability of treatment (receiving the Individual Transferable Quota) -in log odds- increases or decreases with a 1 unit increase in a covariate, while holding all other variables constant. The only covariates that were statistically significant (beyond a significance level of 0.001) were the four variables that I noted in my initial exploration as having unequal distributions: MET4, MET5, IND_SR, and COMM_VAL. For each fishery, the log odds of receiving the Individual Transferable Quota increases by 0.56 if the fishery is a marine ecosystem type 4, and this estimate is significant beyond a significance level of 0.001. For each fishery, the log odds of receiving the Individual Transferable Quota increases by 0.51 if the fishery is a marine ecosystem type 5, and this estimate is significant beyond a significance level of 0.001. For each fishery, the log odds of receiving the Individual Transferable Quota increases by 0.059 if the fishery is a marine ecosystem type 4, and this estimate is significant beyond a significance level of 0.001. For each fishery, the log odds of receiving the Individual Transferable Quota decreased by 0.08 for every one unit increase in the species richness index, and this estimate is significant beyond a significance level of 0.001. For each fishery, the log odds of receiving the Individual Transferable Quota decreases by 0.022 for every one million US dollar increase in the commercial value of the fishery, and this estimate is significant beyond a significance level of 0.001. The Marine Ecosystem Types 1, 2, and 3 all had statistically insignificant estimates of 0.059, 0.16, 0.059 respectively. NOTE: the MET6 covariate was excluded from the analysis because it has perfect colinearity with another one of the pre-treatment variables.

```{r , include=TRUE}
## Propensity Score Estimates
ps <- glm(ITQ ~ MET1 + MET2 + MET3 + MET4 + MET5 + MET6 + IND_SR + COMM_VAL,
data = fish_dat, family = binomial())
summary(ps)

fish_dat$psvalue <- predict(ps, type = "response")
## PS Histogram Unmatched
ps_pre_match_hist <- histbackback(split(
fish_dat$psvalue, fish_dat$ITQ),
main = "Propensity Score Distribution Before Matching",
xlab = c("Control", "Treatment"),
ylab = "Propensity score")


```

(d) **Comment on the overlap, do you have any concerns? Why/why not? [1]**

Yes, I have concerns because you can see almost opposite distributions between the treated and non-treated groups for propensity scores. There is some overlap, but you can see the treated group has a skewed distribution with the bulk of the observations having a propensity score of 0.8. The control group also has a skewed distribution, however the bulk of the observations have a propensity score closer to 0.2. This is a concern for me because there aren't enough observations in the control group to match a valid counter-factual for each observation in the treatment group. This will be even more difficult since the original dataset had fewer observations in the control group than the treated group. When there isn't a valid counter-factual for each treated observation, the propensity score matching doesn't mitigate the issue of unequally distributed pre-treatment characteristics between the treated and non-treated groups.

## ATT with Nearest Neighbor Matching *(3 pts: 2 pt estimate, 1 pt interpretation)*

(e) Use the propensity scores from (c) to estimate the Average Treatment Effect on the Treated (ATT) with a nearest neighbor matching estimator. Interpret the result (just the size of the estimate)

After using nearest neighbor matching, we estimated that the average treatment affect on the treated was roughly -0.07. Interpreted into words, that means providing fisheries with the Individual Transferable Quota reduced the share of years between 1990 and 2012 that the fishery was closed by 0.07, which translates to roughly one and a half years.

It is worth noting you can see from my results that the matching was not done very well. This is caused by an unequal distribution of pre-treatment characteristics that could not be mitigated from matching (all but MET2 had statistically significant differences in the propensity scores). I believe using the nearest neighbor approach tries to keep all the treatment observations, but since there were more treated than non-treated, we were only able to find matches for 5160 of the 5975 treated fisheries. Looking into the documentation, it looks like the matchit function uses "greedy learning" which makes the closest matches but doesn't consider overall accuracy. I'm thinking that's what caused the problem with the poor matching, especially if the matchit function is programmed to start at the highest propensity score and work it's way down. That would've caused the function to drop all of the lowest propensity scores from the treated group when it ran out of options. Because of this poor matching, the provided estimate for ATT is likely a biased estimate.

```{r , include=TRUE}
## Nearest-neighbor Matching
m.nn <- matchit(ITQ ~ MET1 + MET2 + MET3 + MET4 + MET5 + MET6 + IND_SR + COMM_VAL,
data=fish_dat, method= "nearest", ratio = 1)
match.data = match.data(m.nn)
# summary(m.nn)
## Covariate Imbalance post matching:
ps_matched <- xBalance(ITQ ~ MET1 + MET2 + MET3 + MET4 + MET5 + MET6 + IND_SR + COMM_VAL,
                       data=match.data,
                       report=c("std.diffs","chisquare.test", "p.values"))
ps_matched

## Histogram of PS after matching
ps_post_match_hist <- histbackback(split(match.data$psvalue, match.data$ITQ),
main = "Propensity Score Distribution AFTER Matching",
xlab = c("Control", "Treatment"),
ylab = "Propensity score")

## Estimate ATT
## Nearest Neighbor 
## Nearest Neighbor 
diff_data <- match.data %>%
group_by(subclass) %>% # groups each match by their unique match
summarise(diff = mean(COLL_SHARE[ITQ == 1]) - mean(COLL_SHARE[ITQ == 0]),
.groups = 'drop') # calculates the difference of each matched pair (treated- untreated)
# Calculate the mean of all differences for the ATT
ATT <- mean(diff_data$diff, na.rm = TRUE)
ATT
```

## ATE with WLS *(3 pts: 1 pt estimate, 1 pt interpretation)*

(f) Estimate the Average Treatment Effect (ATE) using the weighted least squares on the full sample. Interpret the estimated size and conclude if it is significantly different from zero from a statistical perspective.

Using the Weighted Least Squares approach on the full dataset, I found an estimate for the average treatment effect to be -0.066 with a significance level beyond 0.001. Interpreted into words, the average treatment effect of the Individual Transfer Quota was a decrease of 0.066 in the share of years a fishery was collapsed between 1990 and 2012, which translates to slightly less than one and a half years. This estimate is also statistically significant, so we can reject the null hypotesis that the true ATE is zero. Again, this is likely a baised estimate because the pre-treatment characteristics are not equally distributed between the treated and non-treated groups, so we don't have a valid counter-factual to compare to the treated group.

```{r , include=TRUE}
###### Weighted least Squares (WLS) estimator
PS <- fish_dat$psvalue
Y <- fish_dat$COLL_SHARE
D <- fish_dat$ITQ
# Both the nearest neighbor matching estimator and the IPW estimattor do not
# easily allow to calculated standard errors. They also do not allow to take
# controls into consideration. Therefore the following weighted least squares
# estimator has advantages
# calculation of the weights - see slide 25 of lecture 5
fish_data <- fish_dat %>%
mutate(wgt = (D/PS + (1-D)/(1-PS)))
fish_dat$wgt = ifelse(D == 1, 1 / PS, 1 / (1 - PS))

# Strongly advisable as outcomes depend on controls and including
# them allows to estimate the ATE with more precision
reg_wls_c <-lm(COLL_SHARE ~ ITQ, MET1 + MET2 + MET3 + MET4 + MET5 + MET6 + IND_SR + COMM_VAL,
data = fish_data, weights = wgt)

summary(reg_wls_c)

```

# Part 2 Difference in Difference Estimation *(10 points total + 3pts extra credit)*

\indent Here we return for a final time to the dataset from Gertler, Martinez, and Rubio-Codina (2012) and use a different way of estimating the effect of the Mexican conditional cash transfer on the value of animal holdings of recipients. We'll use the panel data from assignment 2, where you have both the pre-program and post-program observations. See Template for dataset preparation instructions.

\indent \*\*Data Preparation\*\*

\indent \*Note: You will need to install the packages plm and dplyr (included in template preamble). Again, you can find a description of the variables at the bottom of PDF and HERE.

Prepare Data: Load the new data (progresa_pre_1997.csv) and the follow-up data (progresa_post_1999.csv) into R. Note that we created a time denoting variable (with the same name, 'year') in BOTH datasets. Again, you will create a panel dataset by appending the data (i.e. binding the dataset row-wise together creating a single dataset). We want to examine the same outcome variable as before, value of family animal holdings (vani). You will use the full dataset for each estimate. NOTE: you should not change any NAs from the TREATED column in your analysis, as we expect that spillover was likely in this program. NAs will be excluded from your calculations/estimations.

```{r , include=TRUE, echo=FALSE}
rm(list=ls()) # clean environment

## Load/Prep Data
progresa_pre_1997 <- read_csv("data/progresa_pre_1997.csv")
progresa_post_1999 <- read_csv("data/progresa_post_1999.csv")

### Append post to pre dataset 
progresa_full <- rbind(progresa_pre_1997, progresa_post_1999) # same as original
#(note, you can keep NAs in the data- they'll be excluded from any estimates etc)
progresa_full <- progresa_full %>%
  group_by(hhid) %>% filter(n() == 2) %>%
  ungroup()
# This removes all families lost to attrition, 
# in other words. Families who were treated/controls in the program, but did not get measured
# in the second year. This can happen for many reasons with observational data, you often
# lose participants as studies go on for longer periods of time.

rm(progresa_pre_1997, progresa_post_1999) # clean unused data

head(progresa_full)
```

## DiD Estimator, ATE *(5 pts: 3 pts estimate, 2 pts interpretation)*

(a) Calculate the DiD estimator of the treatment effect (ATE) of the program on the value of animal holdings (vani) "manually" i.e. based on group mean values without running a regression. Report and interpret the result (Note: no significance test or standard errors is possible, so you do not need to report these values).

The difference in difference estimates the average treatment effect of the conditional cash transfer program as an increase of 287.9 animal holdings per household. This estimate subtracts the changes in animal holdings for the control group over time from the changes in animal holdings for the treated group over time to account for time-invariant characteristics that changed the average animal holdings per household.

```{r, include=TRUE}

## Estimate ATE with DiD estimator manually. 
treat_97 <- progresa_full %>% 
  filter(year == 1997) %>% 
  filter(treatment == 1)
treat_99 <-  progresa_full %>% 
  filter(year == 1999) %>% 
  filter(treatment == 1)
control_97 <-  progresa_full %>% 
  filter(year == 1997) %>% 
  filter(treatment == 0)
control_99 <- progresa_full %>% 
  filter(year == 1999) %>% 
  filter(treatment == 0)
# You will need to calculate various means to get this estimate
pre_treat <- mean(treat_97$vani)
post_treat <- mean(treat_99$vani)
pre_control <- mean(control_97$vani)
post_control <- mean(control_99$vani)

              
## Compute the Difference-in-Differences
DiD_man = (post_treat - pre_treat) - (post_control - pre_control)
DiD_man
```

## Difference in Difference using OLS *(5 pts)*

(b) Now set up an OLS-regression using group mean values to estimate the same ATE. Interpret the estimated treatment effect [3 pts]. Also interpret the coefficients on the time dummy and the group dummy variable (see interpretation done in class in lecture 9) [2 pts].

\indent \*\*Hints:\*\* You will need to create a new dataframe with a variety of dummy variables to do this. The R example provided with the DiD module (and/or the excel file) should help.

The OLS-regression using group mean values estimates the average treatment effect of the conditional cash transfer program as an increase of 287.9 average animal holdings per household. The time dummy variable had an OLS estimate of -1156.8, which can be interpreted as a 1156.8 decrease in average animal holdings from 1997 to 1999 for both the treated and non-treated groups. The group dummy variable has an OLS estimate of -237.7, which can be interpreted as the average number of animal holdings between the treatment and control groups for the 1997 time period, showing that the treatment group had on average 237.7 fewer animal holdings per household before the program began.

```{r, include=TRUE}

## Create a new data frame for OLS regression
did <- data.frame(
  vani = c(pre_treat, pre_control, post_treat, post_control),
  treated = c(1, 0, 1, 0),
  post_treat = c(0, 0, 1, 1)
)

## Run the OLS regression w/dummies
model <- lm(vani ~ treated + post_treat + treated*post_treat, 
            data = did)

## Report OLS Model results Print the summary of the OLS model
# Get summary of the model
summary(model)

```

# Extra Credit: ATE with OLS using full dataset *(3 pts: 2 pts estimate, 1 pt interpretation)*

(c) Estimate the ATE with an OLS-regression based on the original units as observations (i.e. not with group mean values, you will need to use the entire dataset). Even though the specification is the same as in the regression with the group mean values above, you'll need to create new indicator variables for the treatment group and the post treatment time period as well as their interaction term. Verify that you get the same result as above. Now report also on the precision of the estimation and test whether the estimated coefficient is different from zero.

```{r, include=TRUE}
## Create the dummy variables (you'll need 3)
prog_ols_ate <- progresa_full %>% 
  mutate(post_treat = case_when(
    year == 1999 ~ 1,
    year == 1997 ~ 0,
    TRUE ~ NA_integer_
  ))

## OLS regression
ec_model <- lm(vani ~ treatment + post_treat + treatment*post_treat, 
            data = prog_ols_ate)

# Present Regressions in Table
summary(ec_model)

```

The OLS-regression using the original units as observations estimates the average treatment effect of the conditional cash transfer program as an increase of 287.9 average animal holdings per household. This estimate for the ATE is statistically significant beyond a significance level of 0.05, which is sufficient to reject the null hypothesis that the ATE of the conditional cash transfer program on average animal holdings is zero. The time dummy variable had an OLS estimate of -1156.8, which can be interpreted as a 1156.8 decrease in average animal holdings from 1997 to 1999 for both the treated and non-treated groups. This estimate for the change over time is statistically significant beyond a significance level of 0.001, which is sufficient to reject the null hypothesis that there is no change in the average animal holdings per household between 1997 and 1999. The group dummy variable has an OLS estimate of -237.7, which can be interpreted as the average number of animal holdings between the treatment and control groups for the 1997 time period, showing that the treatment group had on average 237.7 fewer animal holdings per household before the program began. This estimate for the difference in average animal holdings between the two groups is statistically significant beyond a significance level of 0.01, which is sufficient to reject the null hypothesis that there is no difference in the average animal holdings between the treated and non-treated groups prior to the program starting.

## Don't grade, these are just notes for me that I wrote out to help me with the interpretations

Intercept: Number of animal holdings for all available observations (treated and non-treated) in the pre-treatment time period

Treatment: The difference in the number of animal holdings between the treatment and control groups for the 1997 time period

post_treat: Change in average animal holdings from 1997 to 1999 for both the treated and non-treated groups

time\*treated: (ATE) This is the difference in difference
