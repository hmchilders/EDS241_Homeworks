---
title: 'EDS241: Assignment 2'
author: "Heather Childers"
date: "`r format(Sys.time(), "2/9/2024")`"
output:
  html_document:
    toc: no
    df_print: paged
  pdf_document:
    toc: no
    number_sections: yes
header-includes: \setlength{\parindent}{1em} \usepackage{float} \renewcommand{\thesubsection}{Question
  (\alph{subsection})}
---

**Reminders:** Make sure to read through the setup in markdown. Remember to fully report/interpret your results and estimates (in writing) + present them in tables/plots.

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
#Clean Environment
rm(list=ls())

# Setup your coding process in a way that works for you. Ideally use projects to organize your scripts and outputs. You all probably know more about this than us! For this project, I would create a project with all your data and scripts. I often store data on servers rather than my computer which is why I use the code you see below.

# set default chunk options
knitr::opts_chunk$set(fig.width = 4, fig.height = 3, 
                      echo = TRUE, message = FALSE, warning = FALSE)

# load packages
packages=c(
# Necessary for Assignment 2
  "Match","plm", "tidyverse", "MatchIt", "RItools", "Hmisc", "lmtest", "estimatr",
# You decide what works for you, these are the packages I use to display results ect, they may not be the ones you use.

"gridExtra", "stargazer", "kableExtra",
"purrr", "knitr", "broom",
   
  # Some Potentially useful packages from earlier examples
           "stargazer", "here", "tidyr", "dplyr","stringr", "janitor", 
           "cowplot", "ggplot2", "tinytex", "datasets", "tibble") # Used for Mock assignment

for (i in packages) {
  if (require(i,character.only=TRUE)==FALSE) {
    install.packages(i,repos='http://cran.us.r-project.org')
  }
  else {
    require(i,character.only=TRUE)
  }
}

# Disable scientific notation if you want
options(scipen=999)

```

# Part 1 Treatment Ignorability Assumption and Applying Matching Estimators (19 points):

The goal is to estimate the causal effect of maternal smoking during pregnancy on infant birth weight using the treatment ignorability assumptions. The data are taken from the National Natality Detail Files, and the extract "SMOKING_EDS241.csv"' is a random sample of all births in Pennsylvania during 1989-1991. Each observation is a mother-infant pair. The key variables are:

**The outcome and treatment variables are:**

\indent birthwgt=birth weight of infant in grams

\indent tobacco=indicator for maternal smoking

**The control variables are:**

\indent mage (mother's age), meduc (mother's education), mblack (=1 if mother identifies as Black), alcohol (=1 if consumed alcohol during pregnancy), first (=1 if first child), diabete (=1 if mother diabetic), anemia (=1 if mother anemic)

```{r , include=TRUE}

# Load data for Part 1
data <- read_csv(here::here("Homework2", "data", "SMOKING_EDS241.csv"))

```

## Mean Differences, Assumptions, and Covariates *(3 pts)*

a)  What is the mean difference in birth weight of infants with smoking and non-smoking mothers [1 pts]?
b)  Under what assumption does this correspond to the average treatment effect of maternal smoking during pregnancy on infant birth weight [0.5 pts]?
c)  Calculate and create a table demonstrating the differences in the mean proportions/values of covariates observed in smokers and non-smokers (remember to report whether differences are statistically significant) and discuss whether this provides empirical evidence for or against this assumption. Remember that this is observational data. What other quantitative empirical evidence or test could help you assess the former assumption? [1.5 pts: 0.5 pts table, 1 pts discussion]

```{r, include=TRUE}
# Selecting binary and continuous variables from the dataset
pretreat_binary <- data %>%
  select(anemia, diabete, alcohol, mblack, first, tobacco)
pretreat_continuous <- data %>%
  select(tobacco, mage, meduc, birthwgt)
control_binary <- data %>% 
  select(anemia, diabete, alcohol, mblack, first)
control_continuous <- data %>% 
  select(mage, meduc)

# Initialize empty data frames to store results of tests
prop_test_results <- data.frame()
t_test_results <- data.frame()

# Identifying binary variables for proportion tests
binary_vars <- names(control_binary)

for (var in binary_vars) {
  
# Splitting the data into treated and untreated groups for the current variable
treated <- pretreat_binary %>% filter(tobacco == 1) %>% pull(!!sym(var))
untreated <- pretreat_binary %>% filter(tobacco == 0) %>% pull(!!sym(var))

# Performing the proportion test
prop_test_result <- prop.test(x = c(sum(treated), sum(untreated)),
n = c(length(treated), length(untreated)),
correct = FALSE)

# Storing the tidy results of the proportion test in the data frame
prop_test_result_tidy <- broom::tidy(prop_test_result)
prop_test_result_tidy$Variable <- var
prop_test_results <- rbind(prop_test_results, prop_test_result_tidy)
}

# Identifying continuous variables for t-tests
continuous_vars <- names(control_continuous)

for (var in continuous_vars) {
# Dynamically creating the formula for the t-test
formula <- as.formula(paste(var, "~ tobacco"))
# Performing the t-test
t_test_result <- t.test(formula, data = pretreat_continuous)
# Storing the tidy results of the t-test in the data frame
t_test_result_tidy <- broom::tidy(t_test_result)
t_test_result_tidy$Variable <- var
t_test_results <- rbind(t_test_results, t_test_result_tidy)
}

# Combining the results of proportion and t-tests into a single data frame
combined_results <- bind_rows(
prop_test_results %>% select(Variable, estimate1, estimate2, p.value),
t_test_results %>% select(Variable, estimate1, estimate2, p.value)
)
# Creating a table for output using kable and kableExtra
combined_results_table <- kable(combined_results, format = "latex",
                                col.names = c("Variable",
                                              "Proportion or Mean Control",
                                              "Proportion or Mean Treated", "P-Value"),
                                caption = "Treated and Untreated Pre-treatment Proportion and T-Test Results") %>% 
                                kable_styling(font_size = 7, latex_options = "hold_position")
# Displaying the table
combined_results_table
```

## ATE and Covariate Balance *(3 pts)*

b)  Assume that maternal smoking is randomly assigned conditional on the observable covariates listed above. Estimate the effect of maternal smoking on birth weight using an OLS regression with NO linear controls for the covariates [0.5 pts]. Perform the same estimate including the control variables [0.5 pts]. Next, compute indices of covariate imbalance between the treated and non-treated regarding these covariates (see example file from class). Present your results in a table [1 pts]. What do you find and what does it say regarding whether the assumption you mentioned responding to a) is fulfilled? [1 pts]

```{r , include=TRUE}

# ATE Regression univariate


# ATE with covariates


# Present Regression Results


# Covariate balance


# Balance Table 


```

## Propensity Score Estimation *(3 pts)*

c)  Next, estimate propensity scores (i.e. probability of being treated) for the sample, using the provided covariates. Create a regression table reporting the results of the regression and discuss what the covariate coefficients indicate and interpret one coefficient [1.5 pts]. Create histograms of the propensity scores comparing the distributions of propensity scores for smokers ('treated') and non-smokers ('control'), discuss the overlap and what it means [1.5 pts].

```{r , include=TRUE}

## Propensity Scores


## PS Histogram Unmatched 

```

## Matching Balance *(3 pts)*

(d) Next, match treated/control mothers using your estimated propensity scores and nearest neighbor matching. Compare the balancing of pretreatment characteristics (covariates) between treated and non-treated units in the original dataset (from c) with the matched dataset (think about comparing histograms/regressions) [2 pts]. Make sure to report and discuss the balance statistics [1 pts].

```{r , include=TRUE}

## Nearest-neighbor Matching

## Covariate Imbalance post matching: 


## Histogram of PS after matching
```

## ATE with Nearest Neighbor *(3 pts)*

(e) Estimate the ATT using the matched dataset. Report and interpret your result (Note: no standard error or significance test is required here)

```{r , include=TRUE}

## Nearest Neighbor 

## ATT


```

## ATE with WLS Matching *(3 pts)*

f)  Last, use the original dataset and perform the weighted least squares estimation of the ATE using the propensity scores (including controls). Report and interpret your results, here include both size and precision of estimate in reporting and interpretation.

```{r , include=TRUE}
## Weighted least Squares (WLS) estimator Preparation


## Weighted least Squares (WLS) Estimates


## Present Results

```

## Differences in Estimates *(1 pts)*

g)  Explain why it was to be expected given your analysis above that there is a difference between your estimates in e) and f)?

\newpage

# Part 2 Panel model and fixed effects (6 points)

\indent We will use the progresa data from last time as well as a new dataset. In the original dataset, treatment households had been receiving the transfer for a year. Now, you get an additional dataset with information on the same households from before the program was implemented, establishing a baseline study (from 1997), and the same data we worked with last time (from 1999). \indent *Note: You will need to install the packages plm and dplyr (included in template preamble). Again, you can find a description of the variables at the bottom of PDF and HERE.

## Estimating Effect with First Difference *(3 pts: 1.5 pts estimate, 1.5 pts interpretation)*

Setup: Load the new baseline data (progresa_pre_1997.csv) and the follow-up data (progresa_post_1999.csv) into R. Note that we created a time denoting variable (with the same name, 'year') in BOTH datasets. Then, create a panel dataset by appending the data (i.e. binding the dataset row-wise together creating a single dataset). We want to examine the same outcome variable as before, value of animal holdings (vani).

```{r , include=TRUE}
rm(list=ls()) # clean environment

## Load the datasets
# progresa_pre_1997 <- read_csv() insert your filepath etc
# progresa_post_1999 <- read_csv()

## Append post to pre dataset 
#progresa <- rbind(progresa_pre_1997, progresa_post_1999)

```

a)  Estimate a first-difference (FD) regression manually, interpret the results briefly (size of coefficient and precision!) \indent *Note: Calculate the difference between pre- and post- program outcomes for each family. To do that, follow these steps and the code given in the R-template:

```{r, include=TRUE}
### Code included to help get you started
## i. Sort the panel data in the order in which you want to take differences, i.e. by household and time.

## Create first differences of variables
# progresa <- progresa %>% 
#   arrange(hhid, year) %>% 
#   group_by(hhid)

## ii. Calculate the first difference using the lag function from the dplyr package.
#     mutate(vani_fd = vani - dplyr::lag(vani)) 

## iii. Estimate manual first-difference regression (Estimate the regression using the newly created variables.)
fd_manual <- lm(vani_fd ~ ...)

```

## Fixed Effects Estimates *(2 pts: 1 pts estimate, 1.5 interpretation)*

b)  Now also run a fixed effects (FE or 'within') regression and compare the results. Interpret the estimated treatment effects briefly (size of coefficient and precision!)

```{r, include=TRUE}
## Fixed Effects Regression

## Present Regression Results
```

## First Difference and Fixed Effects and Omitted Variable Problems *(1 pts)*

c)  Explain briefly how the FD and FE estimator solves a specific omitted variable problem? Look at the example on beer tax and traffic fatalities from class to start thinking about ommitted variables. Give an example of a potential omitted variable for the example we are working with here that might confound our results? For that omitted variable, is a FE or FD estimator better? One example is enough.
